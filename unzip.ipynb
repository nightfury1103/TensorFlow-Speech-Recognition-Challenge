{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-24T10:48:56.226949Z","iopub.status.busy":"2024-02-24T10:48:56.224371Z","iopub.status.idle":"2024-02-24T10:49:14.729223Z","shell.execute_reply":"2024-02-24T10:49:14.728297Z","shell.execute_reply.started":"2024-02-24T10:48:56.226904Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-25 22:12:51.380001: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-02-25 22:12:51.407417: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-25 22:12:51.407443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-25 22:12:51.408524: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-25 22:12:51.413737: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-02-25 22:12:51.414479: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-02-25 22:12:52.029994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import librosa\n","import librosa.display\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import tqdm\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T10:51:41.773466Z","iopub.status.busy":"2024-02-24T10:51:41.772934Z","iopub.status.idle":"2024-02-24T10:51:46.731243Z","shell.execute_reply":"2024-02-24T10:51:46.729958Z","shell.execute_reply.started":"2024-02-24T10:51:41.773424Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train/audio/_background_noise_/white_noise.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train/audio/_background_noise_/running_tap.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train/audio/_background_noise_/dude_miaowing.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train/audio/_background_noise_/pink_noise.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train/audio/_background_noise_/exercise_bike.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>64722</th>\n","      <td>train/audio/zero/3ff840aa_nohash_0.wav</td>\n","      <td>zero</td>\n","    </tr>\n","    <tr>\n","      <th>64723</th>\n","      <td>train/audio/zero/db7c95b0_nohash_0.wav</td>\n","      <td>zero</td>\n","    </tr>\n","    <tr>\n","      <th>64724</th>\n","      <td>train/audio/zero/637c702a_nohash_1.wav</td>\n","      <td>zero</td>\n","    </tr>\n","    <tr>\n","      <th>64725</th>\n","      <td>train/audio/zero/9e42ae25_nohash_1.wav</td>\n","      <td>zero</td>\n","    </tr>\n","    <tr>\n","      <th>64726</th>\n","      <td>train/audio/zero/f5d09ebd_nohash_0.wav</td>\n","      <td>zero</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>64727 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   path               label\n","0        train/audio/_background_noise_/white_noise.wav  _background_noise_\n","1        train/audio/_background_noise_/running_tap.wav  _background_noise_\n","2      train/audio/_background_noise_/dude_miaowing.wav  _background_noise_\n","3         train/audio/_background_noise_/pink_noise.wav  _background_noise_\n","4      train/audio/_background_noise_/exercise_bike.wav  _background_noise_\n","...                                                 ...                 ...\n","64722            train/audio/zero/3ff840aa_nohash_0.wav                zero\n","64723            train/audio/zero/db7c95b0_nohash_0.wav                zero\n","64724            train/audio/zero/637c702a_nohash_1.wav                zero\n","64725            train/audio/zero/9e42ae25_nohash_1.wav                zero\n","64726            train/audio/zero/f5d09ebd_nohash_0.wav                zero\n","\n","[64727 rows x 2 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# create json dataset with format: \n","# [\n","#   {\n","#     \"path\": \"path/to/audio/file\",\n","#     \"label\": \"label\"\n","#   },\n","#   ...\n","# ]\n","path = 'train/audio'\n","data = []\n","\n","for label in os.listdir(path):\n","    for file in os.listdir(f'{path}/{label}'):\n","        if file == 'README.md':\n","            continue\n","        data.append({\n","            'path': f'{path}/{label}/{file}',\n","            'label': label\n","        })\n","\n","df = pd.DataFrame(data)\n","df"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T10:51:50.528435Z","iopub.status.busy":"2024-02-24T10:51:50.528041Z","iopub.status.idle":"2024-02-24T10:51:50.536449Z","shell.execute_reply":"2024-02-24T10:51:50.534853Z","shell.execute_reply.started":"2024-02-24T10:51:50.528406Z"},"trusted":true},"outputs":[],"source":["def audio_to_spectrogram(file_path, max_pad_len=174):\n","    wave, sr = librosa.load(file_path, mono=True, sr=None)\n","    mfcc = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=20)\n","    pad_width = max_pad_len - mfcc.shape[1]\n","    if pad_width > 0:\n","        mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n","    else:\n","        mfcc = mfcc[:, :max_pad_len]\n","    return mfcc"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T10:51:57.462151Z","iopub.status.busy":"2024-02-24T10:51:57.461730Z","iopub.status.idle":"2024-02-24T10:51:57.481871Z","shell.execute_reply":"2024-02-24T10:51:57.479622Z","shell.execute_reply.started":"2024-02-24T10:51:57.462115Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>train/audio/_background_noise_/white_noise.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>train/audio/_background_noise_/running_tap.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>train/audio/_background_noise_/dude_miaowing.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>train/audio/_background_noise_/pink_noise.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>train/audio/_background_noise_/exercise_bike.wav</td>\n","      <td>_background_noise_</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>64722</th>\n","      <td>train/audio/zero/3ff840aa_nohash_0.wav</td>\n","      <td>zero</td>\n","    </tr>\n","    <tr>\n","      <th>64723</th>\n","      <td>train/audio/zero/db7c95b0_nohash_0.wav</td>\n","      <td>zero</td>\n","    </tr>\n","    <tr>\n","      <th>64724</th>\n","      <td>train/audio/zero/637c702a_nohash_1.wav</td>\n","      <td>zero</td>\n","    </tr>\n","    <tr>\n","      <th>64725</th>\n","      <td>train/audio/zero/9e42ae25_nohash_1.wav</td>\n","      <td>zero</td>\n","    </tr>\n","    <tr>\n","      <th>64726</th>\n","      <td>train/audio/zero/f5d09ebd_nohash_0.wav</td>\n","      <td>zero</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>64727 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                   path               label\n","0        train/audio/_background_noise_/white_noise.wav  _background_noise_\n","1        train/audio/_background_noise_/running_tap.wav  _background_noise_\n","2      train/audio/_background_noise_/dude_miaowing.wav  _background_noise_\n","3         train/audio/_background_noise_/pink_noise.wav  _background_noise_\n","4      train/audio/_background_noise_/exercise_bike.wav  _background_noise_\n","...                                                 ...                 ...\n","64722            train/audio/zero/3ff840aa_nohash_0.wav                zero\n","64723            train/audio/zero/db7c95b0_nohash_0.wav                zero\n","64724            train/audio/zero/637c702a_nohash_1.wav                zero\n","64725            train/audio/zero/9e42ae25_nohash_1.wav                zero\n","64726            train/audio/zero/f5d09ebd_nohash_0.wav                zero\n","\n","[64727 rows x 2 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T10:52:39.624704Z","iopub.status.busy":"2024-02-24T10:52:39.624290Z","iopub.status.idle":"2024-02-24T10:52:41.321386Z","shell.execute_reply":"2024-02-24T10:52:41.319810Z","shell.execute_reply.started":"2024-02-24T10:52:39.624673Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/huy/miniconda3/envs/distill/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","100%|██████████| 64727/64727 [03:14<00:00, 332.03it/s]\n"]}],"source":["from tqdm.auto import tqdm\n","tqdm.pandas()\n","\n","# Apply the function with a progress bar\n","df['spectrogram'] = df['path'].progress_apply(audio_to_spectrogram)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T10:52:46.760973Z","iopub.status.busy":"2024-02-24T10:52:46.760575Z","iopub.status.idle":"2024-02-24T10:52:46.769224Z","shell.execute_reply":"2024-02-24T10:52:46.767914Z","shell.execute_reply.started":"2024-02-24T10:52:46.760943Z"},"trusted":true},"outputs":[],"source":["X = np.array(df['spectrogram'].tolist())\n","X = X[..., np.newaxis]\n","y = np.array(df['label'].tolist())\n","\n","# Assuming `y_train` and `y_test` are your categorical labels\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T10:53:17.082585Z","iopub.status.busy":"2024-02-24T10:53:17.081432Z","iopub.status.idle":"2024-02-24T10:53:17.541074Z","shell.execute_reply":"2024-02-24T10:53:17.539687Z","shell.execute_reply.started":"2024-02-24T10:53:17.082543Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","\n","model = load_model('model.h5')\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T10:55:53.818353Z","iopub.status.busy":"2024-02-24T10:55:53.817966Z","iopub.status.idle":"2024-02-24T10:55:53.825449Z","shell.execute_reply":"2024-02-24T10:55:53.824301Z","shell.execute_reply.started":"2024-02-24T10:55:53.818323Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20, 174, 1)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["X[0].shape"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T10:59:23.314098Z","iopub.status.busy":"2024-02-24T10:59:23.313663Z","iopub.status.idle":"2024-02-24T10:59:23.321938Z","shell.execute_reply":"2024-02-24T10:59:23.320659Z","shell.execute_reply.started":"2024-02-24T10:59:23.314064Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['_background_noise_', '_background_noise_', '_background_noise_',\n","       ..., 'zero', 'zero', 'zero'], dtype='<U18')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["y"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T11:00:11.708903Z","iopub.status.busy":"2024-02-24T11:00:11.708424Z","iopub.status.idle":"2024-02-24T11:00:11.811071Z","shell.execute_reply":"2024-02-24T11:00:11.809647Z","shell.execute_reply.started":"2024-02-24T11:00:11.708866Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 234ms/step\n"]}],"source":["prediction = model.predict(np.expand_dims(X[0], axis=0))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T11:01:06.173314Z","iopub.status.busy":"2024-02-24T11:01:06.172708Z","iopub.status.idle":"2024-02-24T11:01:06.183410Z","shell.execute_reply":"2024-02-24T11:01:06.182464Z","shell.execute_reply.started":"2024-02-24T11:01:06.173275Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted class: [27]\n"]}],"source":["predicted_class = np.argmax(prediction, axis=1)\n","print(f\"Predicted class: {predicted_class}\")\n","\n","# If you have label encoder, you can decode this prediction back to original label\n","# decoded_label = label_encoder.inverse_transform(predicted_class)\n","# print(f\"Predicted label: {decoded_label}\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["array(['up'], dtype='<U18')"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["label_encoder.inverse_transform(predicted_class)"]},{"cell_type":"markdown","metadata":{},"source":["# full test"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>test/audio/clip_726cc12df.wav</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>test/audio/clip_f442b53d8.wav</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>test/audio/clip_ccb6035b1.wav</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>test/audio/clip_fb3a83674.wav</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>test/audio/clip_006f5bc7b.wav</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>158533</th>\n","      <td>test/audio/clip_42eb33be8.wav</td>\n","    </tr>\n","    <tr>\n","      <th>158534</th>\n","      <td>test/audio/clip_6bb7e3b4c.wav</td>\n","    </tr>\n","    <tr>\n","      <th>158535</th>\n","      <td>test/audio/clip_27a90a0cd.wav</td>\n","    </tr>\n","    <tr>\n","      <th>158536</th>\n","      <td>test/audio/clip_c6cc2bbe0.wav</td>\n","    </tr>\n","    <tr>\n","      <th>158537</th>\n","      <td>test/audio/clip_cac2f8fb4.wav</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>158538 rows × 1 columns</p>\n","</div>"],"text/plain":["                                 path\n","0       test/audio/clip_726cc12df.wav\n","1       test/audio/clip_f442b53d8.wav\n","2       test/audio/clip_ccb6035b1.wav\n","3       test/audio/clip_fb3a83674.wav\n","4       test/audio/clip_006f5bc7b.wav\n","...                               ...\n","158533  test/audio/clip_42eb33be8.wav\n","158534  test/audio/clip_6bb7e3b4c.wav\n","158535  test/audio/clip_27a90a0cd.wav\n","158536  test/audio/clip_c6cc2bbe0.wav\n","158537  test/audio/clip_cac2f8fb4.wav\n","\n","[158538 rows x 1 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["path = 'test/audio'\n","data = []\n","\n","for file in os.listdir(f'{path}'):\n","    if file == 'README.md':\n","        continue\n","    data.append({\n","        'path': f'{path}/{file}',\n","    })\n","\n","df = pd.DataFrame(data)\n","df"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 158538/158538 [07:44<00:00, 341.29it/s]\n"]}],"source":["from tqdm.auto import tqdm\n","tqdm.pandas()\n","\n","# Apply the function with a progress bar\n","df['spectrogram'] = df['path'].progress_apply(audio_to_spectrogram)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["X_test = np.array(df['spectrogram'].tolist())\n","X_test = X_test[..., np.newaxis]"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["(158538, 20, 174, 1)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["X_test.shape"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-25 22:41:16.113804: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2206848960 exceeds 10% of free system memory.\n"]},{"name":"stdout","output_type":"stream","text":["4955/4955 [==============================] - 24s 5ms/step\n"]}],"source":["predictions = model.predict(X_test)\n","predicted_classes = np.argmax(predictions, axis=1)\n","predicted = label_encoder.inverse_transform(predicted_classes)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["(158538,)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["predicted.shape"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["df['PredictedLabel'] = predicted"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# extract the file name from the path\n","df['file'] = df['path'].apply(lambda x: x.split('/')[-1])"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["df[['file', 'PredictedLabel']].rename(columns={'file': 'fname', 'PredictedLabel': 'label'}).to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","# Save to CSV\n","df.to_csv('predictions.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('hello')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!rm -r test"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":46676,"sourceId":7634,"sourceType":"competition"},{"sourceId":164098894,"sourceType":"kernelVersion"}],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
